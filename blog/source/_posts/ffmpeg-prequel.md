---
title: ffmpeg音视频前传
date: 2017-10-10 14:00:08
categories: "音视频"
tags:
	- "ffmpeg"
---

<font size=4>

## 1. 为什么要进行视频压缩？

* 未经压缩的数字视频的数据量巨大
* 存储困难
	* 一G只能存储几秒钟的未压缩数字视频。
* 传输困难
	* 1兆的带宽传输一秒的数字电视视频需要大约4分钟。


## 2. 为什么可以压缩
* 去除冗余信息
	* 空间冗余：图像相邻像素之间有较强的相关性
	* 时间冗余：视频序列的相邻图像之间内容相似
	* 编码冗余：不同像素值出现的概率不同
	* 视觉冗余：人的视觉系统对某些细节不敏感
	* 知识冗余：规律性的结构可由先验知识和背景知识得到


## 3. 数据压缩分类
* 无损压缩（Lossless）
	* 压缩前解压缩后图像完全一致X=X'
	* 压缩比低(2:1~3:1)
	* 例如：Winzip，JPEG-LS
* 有损压缩（Lossy）
	* 压缩前解压缩后图像不一致X≠X'
	* 压缩比高(10:1~20:1)
	* 利用人的视觉系统的特性
	* 例如：MPEG-2，H.264/AVC，AVS
	


## 人类视觉系统HVS
* HVS特点：
	* 对高频信息不敏感
	* 对高对比度更敏感
	* 对亮度信息比色度信息更敏感
	* 对运动的信息更敏感
* RGB转化到YUV空间	



主流的编解码标准的压缩对象都是YUV图像

## 播放流程

![音视频播放流程](https://raw.githubusercontent.com/sheltonliu/sheltonliu.github.io/hexo/blog/MarkdownPhotos/2017/10/10/ffmpeg_play.png)

### 1.解协议的作用

就是将流媒体协议的数据，解析为标准的相应的封装格式数据。视音频在网络上传播的时候，常常采用各种流媒体协议，例如HTTP，RTMP，或是MMS等等。这些协议在传输视音频数据的同时，也会传输一些信令数据。
 	信令数据包括对播放的控制（播放，暂停，停止），或者对网络状态的描述等。解协议的过程中会去除掉信令数据而只保留视音频数据。例如，采用RTMP协议传输的数据，经过解协议操作后，输出FLV格式的数据。

### 2.解封装的作用

就是将输入的封装格式的数据，分离成为音频流压缩编码数据和视频流压缩编码数据。封装格式种类很多，例如MP4，MKV，RMVB，TS，FLV，AVI等等，它的作用就是将已经压缩编码的视频数据和音频数据按照一定的格式放到一起。例如，FLV格式的数据，经过解封装操作后，输出H.264编码的视频码流和AAC编码的音频码流。


### 3.解码的作用

就是将视频/音频压缩编码数据，解码成为非压缩的视频/音频原始数据。

音频的压缩编码标准包含AAC，MP3，AC-3等等，视频的压缩编码标准则包含H.264，MPEG2，VC-1等等。

解码是整个系统中最重要也是最复杂的一个环节。通过解码，压缩编码的视频数据输出成为非压缩的颜色数据，例如YUV420P，RGB等等；压缩编码的音频数据输出成为非压缩的音频抽样数据，例如PCM数据。

### 4.视音频同步的作用

就是根据解封装模块处理过程中获取到的参数信息，同步解码出来的视频和音频数据，并将视频音频数据送至系统的显卡


由表可见，除了AVI之外，其他封装格式都支持流媒体，即可以“边下边播”。有些格式更“万能”一些，支持的视音频编码标准多一些，比如MKV。而有些格式则支持的相对比较少，比如说RMVB。
这些封装格式都有相关的文档，在这里就不一一例举了。


## 视频编码

视频编码的主要作用是将视频像素数据（RGB，YUV等）压缩成为视频码流，从而降低视频的数据量。如果视频不经过压缩编码的话，体积通常是非常大的，一部电影可能就要上百G的空间。视频编码是视音频技术中最重要的技术之一。视频码流的数据量占了视音频总数据量的绝大部分。高效率的视频编码在同等的码率下，可以获得更高的视频质量。


## 音频编码

音频编码的主要作用是将音频采样数据（PCM等）压缩成为音频码流，从而降低音频的数据量。音频编码也是互联网视音频技术中一个重要的技术。但是一般情况下音频的数据量要远小于视频的数据量，因而即使使用稍微落后的音频编码标准，而导致音频数据量有所增加，也不会对视音频的总数据量产生太大的影响。高效率的音频编码在同等的码率下，可以获得更高的音质。
音频编码的简单原理 


## YUV420数据格式

YUV简介

YUV定义：分为三个分量，

“Y”表示明亮度（Luminance或Luma）也就是灰度值
而“U”和“V” 表示的则是色度（Chrominance或Chroma），作用是描述影像色彩及饱和度，用于指定像素的颜色。

YUV存储：格式其实与其采样的方式密切相关，主流的采样方式有三种，YUV4:4:4，YUV4:2:2，YUV4:2:0，
YUV特点：也是一种颜色编码方法，它将亮度信息（Y）与色彩信息（UV）分离，没有UV信息一样 可以显示完整的图像，只不过是黑白的，这样的设计很好地解决了彩色电视机与黑白电视的兼容问题。并且，YUV不像RGB那样要求三个独立的视频信号同时传 输，所以用YUV方式传送占用极少的频宽。

在采集到RGB24数据后，需要对这个格式的数据进行第一次压缩。即将图像的颜色空间由RGB2YUV。因为，X264在进行编码的时候需要标准的YUV（4：2：0）。但是这里需要注意的是，虽然YV12也是（4：2：0），但是YV12和I420的却是不同的，在存储空间上面有些区别。如下：
	
YV420： 亮度（行×列） ＋ V（行×列/4) + U（行×列/4）

以后提取每个像素的YUV分量会用到。
	
* 1. YUV 4:4:4采样，每一个Y对应一组UV分量。
* 2. YUV 4:2:2采样，每两个Y共用一组UV分量。 
* 3. YUV 4:2:0采样，每四个Y共用一组UV分量。

  
## ffmpeg函数的作用

	av_register_all
	基于ffmpeg的应用程序中  几乎都是第一个被调用的。
	只有调用了该函数，才能使用复用器，编码器才能起作用，必须调用此函数。
	
	一般来说，直接采集到的视频数据是RGB24的格式，
	RGB24一帧的大小size＝width×heigth×3 Byte，RGB32的size＝width×heigth×4，
	如果是I420（即YUV标准格式4：2：0）的数据量是 size＝width×heigth×1.5 Byte。

 
	AVFormatContext是包含码流参数较多的结构体。本文将会详细分析一下该结构体里每个变量的含义和作用。

	struct AVInputFormat *iformat：输入数据的封装格式
	AVIOContext *pb：输入数据的缓存
	unsigned int nb_streams：视音频流的个数 (视频流，音频流，字幕流  流1，流2 流3 这样)
	AVStream **streams：视音频流
	char filename[1024]：文件名
	int64_t duration：时长（单位：微秒us，转换为秒需要除以1000000）
	int bit_rate：比特率（单位bps，转换为kbps需要除以1000）
	AVDictionary *metadata：元数据

	avformat_find_stream_info
	该函数主要用于给每个媒体流（音频/视频）的AVStream结构体赋值。
	我们大致浏览一下这个函数的代码，会发现它其实已经实现了解码器的查找，
	解码器的打开，视音频帧的读取，视音频帧的解码等工作。
	换句话说，该函数实际上已经“走通”的解码的整个流程。
	下面看一下除了成员变量赋值之外，该函数的几个关键流程。

 
	从avcodec_decode_video2()主要做了以下几个方面的工作：
	（1）对输入的字段进行了一系列的检查工作：例如宽高是否正确，输入是否为视频等等。
	（2）通过ret = avctx->codec->decode(avctx, picture, got_picture_ptr,&tmp)这句代码，调用了相应AVCodec的decode()函数，完成了解码操作。
	（3）对得到的AVFrame的一些字段进行了赋值，例如宽高、像素格式等等。

 
 
 

FFmpeg并没有垃圾回收机制，所分配的空间都需要自己维护。

而由于视频处理过程中数据量是非常大，对于动态内存的使用更要谨慎。

	AVFormatContext 在FFmpeg中有很重要的作用，
	描述一个多媒体文件的构成及其基本信息，存放了视频编解码过程中的大部分信息。
	通常该结构体由avformat_open_input分配
	存储空间，在最后调用avformat_input_close关闭。

AVStream 描述一个媒体流，在解码的过程中，作为AVFormatContext的一个字段存在，不需要单独的处理。

AVpacket 用来存放解码之前的数据，它只是一个容器，其data成员指向实际的数据缓冲区，在解码的过程中可有av_read_frame创建和填充AVPacket中的数据缓冲区，
当数据缓冲区不再使用的时候可以调用av_free_apcket释放这块缓冲区。

AVFrame   存放从AVPacket中解码出来的原始数据，其必须通过av_frame_alloc来创建，通过av_frame_free来释放。和AVPacket类似，AVFrame中也有一块数据缓存空间，
在调用av_frame_alloc的时候并不会为这块缓存区域分配空间，需要使用其他的方法。在解码的过程使用了


两个AVFrame，这两个AVFrame分配缓存空间的方法也不相同

* 一个AVFrame用来存放从AVPacket中解码出来的原始数据，这个AVFrame的数据缓存空间通过调avcodec_decode_video分配和填充。
* 另一个AVFrame用来存放将解码出来的原始数据变换为需要的数据格式（例如RGB，RGBA）的数据，这个AVFrame需要手动的分配数据缓存空间。
  
  
  
  

在摄像头之类编程经常是会碰到YUV格式,而非大家比较熟悉的RGB格式. 我们可以把YUV看成是一个RGB的变种来理解.

YUV的原理是把亮度与色度分离，研究证明,人眼对亮度的敏感超过色度。利用这个原理，可以把色度信息减少一点，人眼也无法查觉这一点。

YUV三个字母中，其中"Y"表示明亮度（Lumina nce或Luma），也就是灰阶值；而"U"和"V"表示的则是色度（Chrominance或Chroma），作用是描述影像色彩及饱和度，用于指定像素的颜色。用这个三个字母好象就是通道命令

使用YUV的优点有两个:

* 一.彩色YUV图像转黑白YUV图像转换非常简单，这一特性用在于电视信号上。

* 二.YUV是数据总尺寸小于RGB格式
   
   
     

